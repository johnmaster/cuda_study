* GPU计算不是指单独的GPU计算，而是指CPU+GPU的异构计算，GPU必须在CPU的调度下才能完成特定任务。
* 起控制作用的CPU称为主机（host），起加速作用的GPU称为设备（device）。
* 主机对设备的调用是通过核函数（kernel function）来实现，
* 一个典型的，简单的CUDA程序的结构
  * `int main() { 主机代码; 核函数的调用; 主机代码}`
* 核函数必须被`__global__`修饰，核函数的返回类型必须是`void`，限定符`__global__`和`void`的次序可随意
* `cudaDeviceSynchronize`的作用是同步主机与设备

* CUDA对能够定义的网格大小和线程块大小做了限制，网格大小在x,y,z三个方向的最大允许值是2^31 - 1, 65535, 65535;线程块大小在x,y,z这三个方向的最大允许值分别是1024,1024和64。另外还要求线程块总的大小，即blockDim.x，blockDim.y,blockDim.z的乘积不能大于1024，也就是说，不管如何定义，一个线程块最多只能有1024个线程。

一个典型的CUDA程序的基本框架
```
头文件包含
常量定义（或者宏定义）
c++自定义函数和CUDA核函数的声明（原型）
int main(void)
{
        分配主机与设备内存
        初始化主机中的数据
        将某些数据从主机复制到设备
        调用核函数在设备中进行计算
        将某些数据从设备复制到主机
        释放主机与设备内存
}
c++自定义函数和CUDA核函数的定义（实现）
```

* 在CUDA中，设备内存的动态分配可由`cudaMalloc`函数实现
  * 函数原型如下`cudaError_t cudaMalloc(void **address, size_t size)`
* `cudaMalloc`函数分配的设备内存需要用`cudaFree()`函数释放
  * 函数原型如下`cudaError_t cudaFree(void *address)`
* `cudaError_t cudaMemcpy(void *dst, const void *src, size_t count, enum cudaMemcpyKind kind)`
  * 第一个参数dst是目标地址
  * 第二个参数src是源地址
  * 第三个参数count是复制数据的字节数
  * 第四个参数kind是枚举类型的变量，标志数据传递方向
    * cudaMemcpyHostToHost, 表示从主机复制到主机
    * cudaMemcpyHostToDevice,表示从主机复制到设备
    * cudaMemcpyDeviceToHost,表示从设备复制到主机
    * cudaMemcpyDeviceToDevice,表示从设备复制到设备
    * cudaMemcpyDefault,表示根据指针dst和src所指地址自动判断数据传输的方向

* 编写核函数时要注意的几点
  * 函数名无特殊要求，而且支持c++中的重载
  * 不支持可变数量的参数列表，参数的个数必须指定
  * 可以向核函数传递非指针变量，其内容对每个线程可见
  * 核函数不能成为一个类的成员，通常的做法是用一个包装函数调用核函数，而将包装函数定义为类的成员
  * 无论是从主机调用还是从设备调用，核函数都是在设备中执行，调用核函数必须指定执行配置，即三括号和它里面的参数
  * 除非使用统一内存编程机制，否则传递给核函数的数组（指针）必须指向设备内存

* 在CUDA程序中，由以下标识符确定一个函数在哪里被调用以及在哪里执行
  * 用`__global__`修饰的函数称为核函数，一般由主机调用，在设备中执行，如果使用动态并行，则也可以在核函数中调用自己或其他核函数
  * 用`__device__`修饰的函数称为设备函数，只能被核函数或其他设备函数调用，在设备中执行
  * 用`__host__`修饰的函数就是主机函数，在主机中被调用，在主机中执行。对于主机端的函数，该修饰符可省略。之所以提供这样的一个修饰符，是因为有时可以用`__host__`和`__device__`同时修饰一个函数，使得该函数既是一个c++的普通函数，又是一个设备函数
  * 不能同时用`__device__`和`__global__`修饰一个函数，即不能将一个函数同时定义为设备函数和核函数
  * 不能同时用`__host__`和`__global__`修饰一个函数，即不能将一个函数同时定义为主机函数和核函数
  * 编译器决定把设备函数当作内联函数或非内联函数，但可以用修饰符`__noinline__`建议一个设备函数为非内联函数，也可以用修饰符`__forceinline__`建议一个设备函数为内联函数
* 有一种方法可以捕捉调用核函数可能发生的错误，即在调用核函数之后加上如下两个语句
  * `CHECK(cudaGetLastError())`
  * `CHECK(cudaDeviceSynchronize())`
  * 第一个语句是捕捉第二个语句之前的最后一个错误，第二个语句的作用是同步主机与设备，因为核函数的调用是异步的，即主机发出调用核函数的命令后会立即执行后面的语句，不会等待核函数执行完毕

* CUDA提供CUDA-MEMCHECK工具
  * cuda-memcheck --tool memcheck [option] app_name [options]
  * cuda-memcheck --tool racecheck [option] app_name [options]
  * cuda-memcheck --tool initcheck [option] app_name [options]
  * cuda-memcheck --tool synccheck [option] app_name [options]
* 提高CUDA程序获得高性能的必要不充分条件
  * 减少主机与设备之间的数据传输
  * 提高核函数的算术强度
  * 增大核函数的并行规模

| 内存类型 | 物理位置 | 访问权限 | 可见范围 | 生命周期 |
| ------ | ------ | ------ | ------ | ------ |
| 全局内存 | 在芯片外 |可读可写 |所有线程和主机端|由主机分配和释放|
|常量内存|在芯片外|仅可读|所有线程和主机端|由主机分配和释放|
|纹理和表面内存|在芯片外|一般仅可读|所有线程和主机端|由主机分配和释放|
|寄存器内存|在芯片内|可读可写|单个线程|所在线程|
|局部内存|在芯片外|可读可写|单个线程|所在线程|
|共享内存|在芯片内|可读可写|单个线程块|所在线程块|

* 全局内存的含义是核函数中的所有线程都能访问其中的数据，全局内存的主要角色是为核函数提供数据，并在主机和设备以及设备和设备之间传递数据，使用`cudaMalloc`函数为全局内存分配设备内存；全局内存对整个网络的所有线程可见，也就是说，一个网格的所有线程都可以访问（读或写）传入核函数的设备指针所指向的全局内存中的全部数据。
* 
